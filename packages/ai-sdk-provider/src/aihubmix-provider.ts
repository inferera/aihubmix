import {
  OpenAIChatLanguageModel,
  OpenAICompletionLanguageModel,
  OpenAIEmbeddingModel,
  OpenAIImageModel,
  OpenAIResponsesLanguageModel,
  OpenAITranscriptionModel,
  OpenAISpeechModel,
} from '@ai-sdk/openai/internal';
import { AnthropicMessagesLanguageModel } from '@ai-sdk/anthropic/internal';
import { GoogleGenerativeAILanguageModel } from '@ai-sdk/google/internal';
import {
  EmbeddingModelV3,
  LanguageModelV3,
  ProviderV3,
  ImageModelV3,
  TranscriptionModelV3,
  SpeechModelV3,
  TranscriptionModelV3CallOptions,
} from '@ai-sdk/provider';
import {
  FetchFunction,
  loadApiKey,
  zodSchema,
  lazySchema,
  type InferSchema,
} from '@ai-sdk/provider-utils';
import { z } from 'zod';
import { aihubmixTools } from './aihubmix-tools';

/**
 * OpenAI Chat è¯­è¨€æ¨¡å‹çš„ Provider Options Schema
 * ä¸ Vercel AI SDK çš„ openaiChatLanguageModelOptions ä¿æŒä¸€è‡´
 */
export const aihubmixChatProviderOptionsSchema = lazySchema(() =>
  zodSchema(
    z.object({
      /**
       * ä¿®æ”¹æŒ‡å®š token å‡ºç°åœ¨ç”Ÿæˆå†…å®¹ä¸­çš„æ¦‚ç‡
       * æ¥å—ä¸€ä¸ª JSON å¯¹è±¡ï¼Œå°† token IDï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰æ˜ å°„åˆ° -100 åˆ° 100 ä¹‹é—´çš„åå·®å€¼
       */
      logitBias: z.record(z.string(), z.number()).optional(),

      /**
       * è¿”å› token çš„å¯¹æ•°æ¦‚ç‡
       * è®¾ç½®ä¸º true è¿”å›ç”Ÿæˆ token çš„å¯¹æ•°æ¦‚ç‡
       * è®¾ç½®ä¸ºæ•°å­—è¿”å›å‰ n ä¸ª token çš„å¯¹æ•°æ¦‚ç‡
       */
      logprobs: z.union([z.boolean(), z.number()]).optional(),

      /**
       * æ˜¯å¦å¯ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ï¼Œé»˜è®¤ä¸º true
       */
      parallelToolCalls: z.boolean().optional(),

      /**
       * ä»£è¡¨ç»ˆç«¯ç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå¸®åŠ© OpenAI ç›‘æ§å’Œæ£€æµ‹æ»¥ç”¨è¡Œä¸º
       */
      user: z.string().optional(),

      /**
       * æ¨ç†æ¨¡å‹çš„æ¨ç†å¼ºåº¦ï¼Œé»˜è®¤ä¸º `medium`
       */
      reasoningEffort: z
        .enum(['none', 'minimal', 'low', 'medium', 'high', 'xhigh'])
        .optional(),

      /**
       * ç”Ÿæˆçš„æœ€å¤§å®Œæˆ token æ•°ï¼Œé€‚ç”¨äºæ¨ç†æ¨¡å‹
       */
      maxCompletionTokens: z.number().optional(),

      /**
       * æ˜¯å¦åœ¨ Responses API ä¸­å¯ç”¨æŒä¹…åŒ–
       */
      store: z.boolean().optional(),

      /**
       * ä¸è¯·æ±‚å…³è”çš„å…ƒæ•°æ®
       */
      metadata: z.record(z.string().max(64), z.string().max(512)).optional(),

      /**
       * é¢„æµ‹æ¨¡å¼çš„å‚æ•°
       */
      prediction: z.record(z.string(), z.any()).optional(),

      /**
       * è¯·æ±‚çš„æœåŠ¡å±‚çº§
       * - 'auto': é»˜è®¤æœåŠ¡å±‚çº§
       * - 'flex': 50% æ›´ä¾¿å®œä½†å»¶è¿Ÿæ›´é«˜ï¼ˆä»…é™ o3, o4-mini, gpt-5ï¼‰
       * - 'priority': æ›´å¿«å¤„ç†ï¼ˆéœ€è¦ä¼ä¸šç‰ˆï¼‰
       * - 'default': æ ‡å‡†å®šä»·å’Œæ€§èƒ½
       */
      serviceTier: z.enum(['auto', 'flex', 'priority', 'default']).optional(),

      /**
       * æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼çš„ JSON schema éªŒè¯
       * @default true
       */
      strictJsonSchema: z.boolean().optional(),

      /**
       * æ§åˆ¶æ¨¡å‹å“åº”çš„è¯¦ç»†ç¨‹åº¦
       * è¾ƒä½çš„å€¼ä¼šäº§ç”Ÿæ›´ç®€æ´çš„å“åº”ï¼Œè¾ƒé«˜çš„å€¼ä¼šäº§ç”Ÿæ›´è¯¦ç»†çš„å“åº”
       */
      textVerbosity: z.enum(['low', 'medium', 'high']).optional(),

      /**
       * æç¤ºç¼“å­˜çš„ç¼“å­˜é”®
       */
      promptCacheKey: z.string().optional(),

      /**
       * æç¤ºç¼“å­˜çš„ä¿ç•™ç­–ç•¥
       * - 'in_memory': é»˜è®¤ï¼Œæ ‡å‡†æç¤ºç¼“å­˜è¡Œä¸º
       * - '24h': æ‰©å±•æç¤ºç¼“å­˜ï¼Œä¿æŒç¼“å­˜å‰ç¼€æœ€å¤š 24 å°æ—¶
       */
      promptCacheRetention: z.enum(['in_memory', '24h']).optional(),

      /**
       * ç”¨äºå¸®åŠ©æ£€æµ‹è¿åä½¿ç”¨æ”¿ç­–ç”¨æˆ·çš„ç¨³å®šæ ‡è¯†ç¬¦
       */
      safetyIdentifier: z.string().optional(),

      /**
       * è¦†ç›–æ­¤æ¨¡å‹çš„ç³»ç»Ÿæ¶ˆæ¯æ¨¡å¼
       * - 'system': ä½¿ç”¨ 'system' è§’è‰²ï¼ˆå¤§å¤šæ•°æ¨¡å‹çš„é»˜è®¤å€¼ï¼‰
       * - 'developer': ä½¿ç”¨ 'developer' è§’è‰²ï¼ˆæ¨ç†æ¨¡å‹ä½¿ç”¨ï¼‰
       * - 'remove': å®Œå…¨ç§»é™¤ç³»ç»Ÿæ¶ˆæ¯
       */
      systemMessageMode: z.enum(['system', 'developer', 'remove']).optional(),

      /**
       * å¼ºåˆ¶å°†æ­¤æ¨¡å‹è§†ä¸ºæ¨ç†æ¨¡å‹
       * é€‚ç”¨äºè‡ªå®šä¹‰ baseURL çš„"éšå½¢"æ¨ç†æ¨¡å‹
       */
      forceReasoning: z.boolean().optional(),
    }),
  ),
);

/**
 * OpenAI Responses API çš„ Provider Options Schema
 */
export const aihubmixResponsesProviderOptionsSchema = lazySchema(() =>
  zodSchema(
    z.object({
      /**
       * OpenAI å¯¹è¯çš„ IDï¼Œç”¨äºç»§ç»­å¯¹è¯
       */
      conversation: z.string().nullish(),

      /**
       * å“åº”ä¸­åŒ…å«çš„é¢å¤–å­—æ®µ
       */
      include: z
        .array(
          z.enum([
            'reasoning.encrypted_content',
            'file_search_call.results',
            'message.output_text.logprobs',
          ]),
        )
        .nullish(),

      /**
       * æ¨¡å‹çš„æŒ‡ä»¤
       */
      instructions: z.string().nullish(),

      /**
       * è¿”å› token çš„å¯¹æ•°æ¦‚ç‡
       */
      logprobs: z
        .union([z.boolean(), z.number().min(1).max(20)])
        .optional(),

      /**
       * å†…ç½®å·¥å…·è°ƒç”¨çš„æœ€å¤§æ€»æ•°
       */
      maxToolCalls: z.number().nullish(),

      /**
       * ä¸ç”Ÿæˆå…³è”çš„é¢å¤–å…ƒæ•°æ®
       */
      metadata: z.any().nullish(),

      /**
       * æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ï¼Œé»˜è®¤ä¸º true
       */
      parallelToolCalls: z.boolean().nullish(),

      /**
       * ä¸Šä¸€ä¸ªå“åº”çš„ IDï¼Œç”¨äºç»§ç»­å¯¹è¯
       */
      previousResponseId: z.string().nullish(),

      /**
       * æç¤ºç¼“å­˜é”®
       */
      promptCacheKey: z.string().nullish(),

      /**
       * æç¤ºç¼“å­˜ä¿ç•™ç­–ç•¥
       */
      promptCacheRetention: z.enum(['in_memory', '24h']).nullish(),

      /**
       * æ¨ç†æ¨¡å‹çš„æ¨ç†å¼ºåº¦
       */
      reasoningEffort: z.string().nullish(),

      /**
       * æ§åˆ¶æ¨ç†æ‘˜è¦è¾“å‡º
       */
      reasoningSummary: z.string().nullish(),

      /**
       * å®‰å…¨ç›‘æ§çš„æ ‡è¯†ç¬¦
       */
      safetyIdentifier: z.string().nullish(),

      /**
       * è¯·æ±‚çš„æœåŠ¡å±‚çº§
       */
      serviceTier: z.enum(['auto', 'flex', 'priority', 'default']).nullish(),

      /**
       * æ˜¯å¦å­˜å‚¨ç”Ÿæˆå†…å®¹ï¼Œé»˜è®¤ä¸º true
       */
      store: z.boolean().nullish(),

      /**
       * æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼çš„ JSON schema éªŒè¯
       */
      strictJsonSchema: z.boolean().nullish(),

      /**
       * æ§åˆ¶æ¨¡å‹å“åº”çš„è¯¦ç»†ç¨‹åº¦
       */
      textVerbosity: z.enum(['low', 'medium', 'high']).nullish(),

      /**
       * è¾“å‡ºæˆªæ–­æ§åˆ¶
       */
      truncation: z.enum(['auto', 'disabled']).nullish(),

      /**
       * ä»£è¡¨ç»ˆç«¯ç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†ç¬¦
       */
      user: z.string().nullish(),

      /**
       * ç³»ç»Ÿæ¶ˆæ¯æ¨¡å¼
       */
      systemMessageMode: z.enum(['system', 'developer', 'remove']).optional(),

      /**
       * å¼ºåˆ¶å°†æ¨¡å‹è§†ä¸ºæ¨ç†æ¨¡å‹
       */
      forceReasoning: z.boolean().optional(),
    }),
  ),
);

// Provider Options ç±»å‹æ¨æ–­
export type AihubmixChatProviderOptions = InferSchema<
  typeof aihubmixChatProviderOptionsSchema
>;

export type AihubmixResponsesProviderOptions = InferSchema<
  typeof aihubmixResponsesProviderOptionsSchema
>;

// OpenAI Provider è®¾ç½®ç±»å‹ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
type OpenAIProviderSettings = AihubmixChatProviderOptions;


export interface AihubmixProvider extends ProviderV3 {
  (deploymentId: string, settings?: OpenAIProviderSettings): LanguageModelV3;

  readonly specificationVersion: 'v3';

  languageModel(
    deploymentId: string,
    settings?: OpenAIProviderSettings,
  ): LanguageModelV3;

  chat(
    deploymentId: string,
    settings?: OpenAIProviderSettings,
  ): LanguageModelV3;

  responses(deploymentId: string): LanguageModelV3;

  completion(
    deploymentId: string,
    settings?: OpenAIProviderSettings,
  ): LanguageModelV3;

  embedding(
    deploymentId: string,
    settings?: OpenAIProviderSettings,
  ): EmbeddingModelV3;

  embeddingModel(modelId: string): EmbeddingModelV3;

  image(deploymentId: string, settings?: OpenAIProviderSettings): ImageModelV3;

  imageModel(modelId: string): ImageModelV3;

  textEmbedding(
    deploymentId: string,
    settings?: OpenAIProviderSettings,
  ): EmbeddingModelV3;

  textEmbeddingModel(
    deploymentId: string,
    settings?: OpenAIProviderSettings,
  ): EmbeddingModelV3;

  transcription(deploymentId: string): TranscriptionModelV3;

  speech(deploymentId: string): SpeechModelV3;

  speechModel(deploymentId: string): SpeechModelV3;

  tools: typeof aihubmixTools;
}
export interface AihubmixProviderSettings {
  apiKey?: string;
  fetch?: FetchFunction;
  compatibility?: 'strict' | 'compatible';
}

class AihubmixTranscriptionModel extends OpenAITranscriptionModel {
  async doGenerate(options: TranscriptionModelV3CallOptions) {
    // æ ¹æ®MIMEç±»å‹è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶æ‰©å±•å
    if (options.mediaType) {
      const mimeTypeMap: Record<string, string> = {
        'audio/mpeg': 'mp3',
        'audio/mp3': 'mp3',
        'audio/wav': 'wav',
        'audio/flac': 'flac',
        'audio/m4a': 'm4a',
        'audio/mp4': 'mp4',
        'audio/ogg': 'ogg',
        'audio/webm': 'webm',
        'audio/oga': 'oga',
        'audio/mpga': 'mpga',
      };
      
      const extension = mimeTypeMap[options.mediaType];
      if (extension) {
        // é‡å†™getArgsæ–¹æ³•æ¥è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶å
        const originalGetArgs = (this as any).getArgs;
        (this as any).getArgs = async function(args: any) {
          const result = await originalGetArgs.call(this, args);
          if (result.formData) {
            // æ‰¾åˆ°fileå­—æ®µå¹¶ä¿®æ”¹æ–‡ä»¶å
            const fileEntry = result.formData.get('file');
            if (fileEntry && typeof fileEntry === 'object' && 'name' in fileEntry) {
              // åˆ›å»ºæ–°çš„ File å¯¹è±¡ï¼Œè®¾ç½®æ­£ç¡®çš„æ–‡ä»¶å
              try {
                const newFile = new File([fileEntry], `audio.${extension}`, { 
                  type: options.mediaType 
                });
                result.formData.set('file', newFile);
              } catch (error) {
                console.log('Failed to create new File object:', error);
                // å¦‚æœåˆ›å»ºæ–° File å¯¹è±¡å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                // åœ¨ Node.js ç¯å¢ƒä¸­ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ Buffer æˆ–å…¶ä»–æ–¹å¼
                if (fileEntry && typeof fileEntry === 'object' && 'arrayBuffer' in fileEntry) {
                  try {
                    const arrayBuffer = await (fileEntry as any).arrayBuffer();
                    const newFile = new File([arrayBuffer], `audio.${extension}`, { 
                      type: options.mediaType 
                    });
                    result.formData.set('file', newFile);
                    console.log('Created new file from arrayBuffer with name:', `audio.${extension}`);
                  } catch (bufferError) {
                    console.log('Failed to create file from arrayBuffer:', bufferError);
                  }
                }
              }
            }
          }
          return result;
        };
      }
    }
    
    return super.doGenerate(options);
  }
}

// è‡ªå®šä¹‰ OpenAI èŠå¤©æ¨¡å‹ç±»ï¼Œä¿®å¤ç©ºå·¥å…·æ—¶çš„ tool_choice é—®é¢˜
class AihubmixOpenAIChatLanguageModel extends OpenAIChatLanguageModel {
  constructor(modelId: string, settings: any) {
    super(modelId, {
      ...settings,
      fetch: AihubmixOpenAIChatLanguageModel.createCustomFetch(settings.fetch),
    });
  }

  private static createCustomFetch(originalFetch?: any) {
    return async (url: string, options: any) => {
      // æ‹¦æˆªè¯·æ±‚å¹¶ä¿®å¤ tool_choice é—®é¢˜
      if (options?.body) {
        try {
          const body = JSON.parse(options.body);
          if (body.tools && Array.isArray(body.tools) && body.tools.length === 0 && body.tool_choice) {
            delete body.tool_choice;
            options.body = JSON.stringify(body);
          }
          // è°ƒè¯•ï¼šæ‰“å° max_tokens å‚æ•°
          if (body.max_tokens !== undefined) {
            console.log('ğŸ” [DEBUG] Request max_tokens:', body.max_tokens);
          }
        } catch (error) {
          // å¦‚æœè§£æå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è¯·æ±‚
        }
      }
      
      return originalFetch ? originalFetch(url, options) : fetch(url, options);
    };
  }
}export function createAihubmix(
  options: AihubmixProviderSettings = {},
): AihubmixProvider {
  const getHeaders = () => ({
    Authorization: `Bearer ${loadApiKey({
      apiKey: options.apiKey,
      environmentVariableName: 'AIHUBMIX_API_KEY',
      description: 'Aihubmix',
    })}`,
    'APP-Code': 'WHVL9885',
    'Content-Type': 'application/json',
  });

  const getTranscriptionHeaders = () => ({
    Authorization: `Bearer ${loadApiKey({
      apiKey: options.apiKey,
      environmentVariableName: 'AIHUBMIX_API_KEY',
      description: 'Aihubmix',
    })}`,
    'APP-Code': 'WHVL9885',
  });

  const url = ({ path, modelId }: { path: string; modelId: string }) => {
    const baseURL = 'https://aihubmix.com/v1';
    return `${baseURL}${path}`;
  };

  const createChatModel = (
    deploymentName: string,
    settings: OpenAIProviderSettings = {},
  ) => {
    const headers = getHeaders();
    if (deploymentName.startsWith('claude-')) {
      return new AnthropicMessagesLanguageModel(deploymentName, {
        provider: 'aihubmix.chat',
        baseURL: url({ path: '', modelId: deploymentName }),
        headers: {
          ...headers,
          'x-api-key': headers['Authorization'].split(' ')[1],
        },
        supportedUrls: () => ({
          'image/*': [/^https?:\/\/.*$/],
        }),
      });
    }
    if (
      (deploymentName.startsWith('gemini') ||
        deploymentName.startsWith('imagen')) &&
      !deploymentName.endsWith('-nothink') &&
      !deploymentName.endsWith('-search')
    ) {
      return new GoogleGenerativeAILanguageModel(
        deploymentName,
        {
          provider: 'aihubmix.chat',
          baseURL: 'https://aihubmix.com/gemini/v1beta',
          headers: {
            ...headers,
            'x-goog-api-key': headers['Authorization'].split(' ')[1],
          },
          generateId: () => `aihubmix-${Date.now()}`,
          supportedUrls: () => ({}),
        },
      );
    }

    if (deploymentName === "gpt-5-pro" || deploymentName === "gpt-5-codex") {
      console.log('responses request', deploymentName);
			return new OpenAIResponsesLanguageModel(deploymentName, {
				provider: 'aihubmix.chat',
				url,
				headers: getHeaders,
				fetch: options.fetch,
				fileIdPrefixes: ['file-'],
			});
		}

    return new AihubmixOpenAIChatLanguageModel(deploymentName, {
      provider: 'aihubmix.chat',
      url,
      headers: getHeaders,
      fetch: options.fetch,
    });
  };

  const createCompletionModel = (
    modelId: string,
    settings: any = {},
  ) =>
    new OpenAICompletionLanguageModel(modelId, {
      provider: 'aihubmix.completion',
      url,
      headers: getHeaders,
      fetch: options.fetch,
    });

  const createEmbeddingModel = (
    modelId: string,
    settings: any = {},
  ) => {
    return new OpenAIEmbeddingModel(modelId, {
      provider: 'aihubmix.embeddings',
      headers: getHeaders,
      url,
      fetch: options.fetch,
    });
  };

  const createResponsesModel = (modelId: string) =>
    new OpenAIResponsesLanguageModel(modelId, {
      provider: 'aihubmix.responses',
      url,
      headers: getHeaders,
      fetch: options.fetch,
      fileIdPrefixes: ['file-'],
    });

  const createImageModel = (
    modelId: string,
    settings: any = {},
  ) => {
    return new OpenAIImageModel(modelId, {
      provider: 'aihubmix.image',
      url,
      headers: getHeaders,
      fetch: options.fetch,
    });
  };

  const createTranscriptionModel = (modelId: string) =>
    new AihubmixTranscriptionModel(modelId, {
      provider: 'aihubmix.transcription',
      url,
      headers: getTranscriptionHeaders,
      fetch: options.fetch,
    });
  const createSpeechModel = (modelId: string) =>
    new OpenAISpeechModel(modelId, {
      provider: 'aihubmix.speech',
      url,
      headers: getHeaders,
      fetch: options.fetch,
    });

  const providerFn = function (
    deploymentId: string,
    settings?: OpenAIProviderSettings,
  ) {
    if (new.target) {
      throw new Error(
        'The Aihubmix model function cannot be called with the new keyword.',
      );
    }

    return createChatModel(deploymentId, settings);
  };

  // åˆ›å»ºå¸¦æœ‰æ‰€æœ‰å¿…éœ€å±æ€§çš„ provider å¯¹è±¡
  const provider = Object.assign(providerFn, {
    specificationVersion: 'v3' as const,
    languageModel: createChatModel,
    chat: createChatModel,
    completion: createCompletionModel,
    responses: createResponsesModel,
    embedding: createEmbeddingModel,
    embeddingModel: createEmbeddingModel,
    textEmbedding: createEmbeddingModel,
    textEmbeddingModel: createEmbeddingModel,
    image: createImageModel,
    imageModel: createImageModel,
    transcription: createTranscriptionModel,
    transcriptionModel: createTranscriptionModel,
    speech: createSpeechModel,
    speechModel: createSpeechModel,
    tools: aihubmixTools,
  });

  return provider as AihubmixProvider;
}

export const aihubmix = createAihubmix();
